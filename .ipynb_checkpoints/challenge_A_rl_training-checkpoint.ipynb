{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **RL4AA'25 Challenge Part 2:** Option RL\n",
    "\n",
    "In this notebook you can solve the RL challenge by training your own RL agent. If you are a beginner in RL, we recommend you stick the with provided code using the PPO implementation from _Stable Baselines3_, and try to tune the hyperparameters of both the environment and the PPO algorithm through the `config` dictionary. If you are more experienced, feel free to change the algorithm or move to a completely different RL library altogether, provided you believe that it will help you solve the challenge.\n",
    "\n",
    "## IMPORTANT: PLEASE READ BEFORE RUNNING THE NOTEBOOK\n",
    "\n",
    "Training a good RL agent can take a lot of time. The task in this challenge was designed such that 500,000 steps should be enough to solve it well. (Though you can train longer if you think you can do better. ðŸ˜‰) On a Mac with an Apple-made SoC, such a training should be doable in about 10 minutes. It may take longer on other machines, expect at least 30 minutes on a recent Windows or Linux laptop.\n",
    "\n",
    "**More importantly** this training can use a considerable amount of RAM. In the worst case, this can also cause other applications to crash when you start training. So please make sure you have nothing unsaved open on your computer before you start training, and that you follow the instructions on setting `n_envs` correctly. When in doubt use a lower number.\n",
    "\n",
    "The following code also uses (_Weight & Biases_)[https://wandb.ai] to log the training. We recommend you create a free account there and check out the results to better understand what is happening during training. If you don't want to use _Weight & Biases_, run `wandb disabled` in a terminal in the root of this repository. You can then still use Tensorboard to visualise the training progress by running `tensorboard --logdir log/` in a terminal in the root of this repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from rl_zoo3 import linear_schedule\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "import wandb\n",
    "from src.eval import Study\n",
    "from src.eval.eval_rl_v3_sim import evaluate_policy\n",
    "from src.train.ea_ppo import make_env\n",
    "from src.utils import load_config, save_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the RL training with the PPO algorithm from _Stable Baselines3_\n",
    "\n",
    "Below you find the `config` dictionary that contains all the hyperparameters for the PPO algorithm and the environment. You can change the values to optimise the training of your agent.\n",
    "\n",
    "You may also modify the `_get_reward` method of the environment to change the reward function. It can be found in [`src/environments/ea.py` line 338](src/environments/ea.py:338).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # ===== Environment parameters =====\n",
    "    # You may change any of these. However, be aware that in the evaluation, some of\n",
    "    # these parameters are set to different values, regardless of what you set in\n",
    "    # the training. It may or may not make sense to change them here. You will just have\n",
    "    # to find out what happens yourself.\n",
    "    # ---------------------\n",
    "    # Choose weather actions set magnet settings directly (`\"direct\"`) or change magnet\n",
    "    # settings (`\"delta\"`)\n",
    "    \"action_mode\": \"delta\",\n",
    "    # Maximum allowed quadrupole setting. The real quadrupoles can be set from -72 to\n",
    "    # 72. These limits are imposed by the power supplies, but are unreasonably high to\n",
    "    # the task at hand. It might therefore make sense to choose a lower value.\n",
    "    \"max_quad_setting\": 30.0,\n",
    "    # Limit of by how much quadrupole settings may be changed when `action_mode` is set\n",
    "    # to `\"delta\"`. This parameter is ignored when `action_mode` is set to `\"direct\"`.\n",
    "    \"max_quad_delta\": 30.0,\n",
    "    # Limit of by how much steerer settings may be changed when `action_mode` is set to\n",
    "    # `\"delta\"`. This parameter is ignored when `action_mode` is set to `\"direct\"`.\n",
    "    \"max_steerer_delta\": 6.1782e-3,\n",
    "    # Magnet initialisation on `reset`. Set to `None` for magnets to stay at their\n",
    "    # current settings, `\"random\"` to be set to random settings or an array of five\n",
    "    # values to set them to a constant value.\n",
    "    \"magnet_init_mode\": np.array([10.0, -10.0, 0.0, 10.0, 0.0]),\n",
    "    # Setting for incoming beam parameters on reset. Can be `\"random\"` to generate\n",
    "    # random parameters or an array of 11 values to set them to a constant value.\n",
    "    \"incoming_mode\": \"random\",\n",
    "    # Setting for misalignment of magnets and the diagnostic screen on reset. Can be\n",
    "    # `\"random\"` to generate random misalignments or an array of 8 values to set them to\n",
    "    # a constant value.\n",
    "    # NOTE: This is fixed to `\"random\"` in the evaluation.\n",
    "    \"misalignment_mode\": \"random\",\n",
    "    # Maximum misalignment of magnets and the diagnostic screen in meters when\n",
    "    # `misalignment_mode` is set to `\"random\"`. This parameter is ignored when\n",
    "    # `misalignment_mode` is set to a constant value.\n",
    "    # NOTE: This is fixed to `5e-4` in the evaluation.\n",
    "    \"max_misalignment\": 5e-4,\n",
    "    # If `True`, the screen is assumed to be finite and false false beam parameters are\n",
    "    # returned when the beam is not on the screen. The false beam parameters are\n",
    "    # estimates of what would be measured on the real screen as a result of the camera\n",
    "    # vignetting when no beam is visible.\n",
    "    # NOTE: That these false beam parameters would always be returned and therefore also\n",
    "    # be used for the reward computation.\n",
    "    # NOTE: This is fixed to `True` in the evaluation.`\n",
    "    \"simulate_finite_screen\": False,\n",
    "    # Setting of target beam on `reset`. Set to \"random\" to generate a random target\n",
    "    # beam or to an array of four values to set it to a constant value.\n",
    "    # NOTE: This is fixed to `\"np.zeros(4)\"` in the evaluation. You can try training on\n",
    "    # random, but this is significantly harder and out of scope for this challenge.\n",
    "    \"target_beam_mode\": np.zeros(4),\n",
    "    # If `True`, magnet settings are clipped to their allowed ranges after each step.\n",
    "    \"clip_magnets\": True,\n",
    "    # ===== Wrapper parameters =====\n",
    "    # Number of observations into the past that are passed to the policy. A value of 1\n",
    "    # means that only the current observation is passed.\n",
    "    \"frame_stack\": 1,\n",
    "    # Whether to scale the observations from their physical ranges to a range of [-1, 1]\n",
    "    # before passing them to the policy.\n",
    "    \"normalize_observation\": True,\n",
    "    # Whether to expect the policy to output actions in the range of [-1, 1] (`True`) or\n",
    "    # in the physical range of the actions (`False`).\n",
    "    \"rescale_action\": True,\n",
    "    # NOTE: Please do not change the `target_threshold` parameter.\n",
    "    \"target_threshold\": None,\n",
    "    # Number of steps per episode allowed during training before the environment is\n",
    "    # reset.\n",
    "    # NOTE: In the evaluation policies will be run for an arbitrary number of steps.\n",
    "    \"max_episode_steps\": 50,\n",
    "    # ===== RL algorithm parameters =====\n",
    "    # Please refer to the Stable Baselines3 documentation for the meaning of these\n",
    "    # parameters:\n",
    "    #   https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html#parameters\n",
    "    # NOTE: Good settings of `n_steps` and `n_envs` depend a lot on your hardware, and\n",
    "    # they depend on each other. We recommend using one of the following options based\n",
    "    # on your hardware:\n",
    "    #   - 32 GB RAM or more: `n_envs=40`, `n_steps=64`\n",
    "    #   - 16 GB RAM: `n_envs=20`, `n_steps=128`\n",
    "    #   - 8 GB RAM: `n_envs=10`, `n_steps=256`\n",
    "    # USING TOO LARGE VALUES MAY CAUSE OTHER APPLICATIONS TO CRASH WITHOUT WARNING!!!\n",
    "    \"batch_size\": 64,\n",
    "    \"learning_rate\": 0.0003,\n",
    "    \"lr_schedule\": \"constant\",  # Can be \"constant\" or \"linear\"\n",
    "    \"gamma\": 0.7,\n",
    "    \"n_envs\": 10,\n",
    "    \"n_steps\": 256,\n",
    "    \"ent_coef\": 0.0,\n",
    "    \"n_epochs\": 50,\n",
    "    \"gae_lambda\": 0.95,\n",
    "    \"clip_range\": 0.2,\n",
    "    \"clip_range_vf\": None,  # None,\n",
    "    \"vf_coef\": 0.5,\n",
    "    \"max_grad_norm\": 0.5,\n",
    "    \"use_sde\": False,\n",
    "    \"sde_sample_freq\": -1,\n",
    "    \"target_kl\": None,\n",
    "    \"total_timesteps\": 250_000,\n",
    "    # ===== Policy parameters =====\n",
    "    # Size of the policy network. Can be \"small\" or \"medium\". Alternatively define\n",
    "    # custom layer sizes below.\n",
    "    \"net_arch\": \"small\",\n",
    "    # Activation function of the policy network. Can be \"Tanh\", \"ReLU\" or \"GELU\".\n",
    "    \"activation_fn\": \"Tanh\",\n",
    "    # Whether or not to use orthogonal initialisation of the policy network weights.\n",
    "    \"ortho_init\": True,  # True, False\n",
    "    # Initial value of the log standard deviation of the policy network output.\n",
    "    \"log_std_init\": 0.0,\n",
    "    # ===== SB3 configuration =====\n",
    "    # PyTorch device used for training. You should probably leave this at \"auto\".\n",
    "    \"sb3_device\": \"auto\",\n",
    "    # Setting for how parallel environments for training rollouts handled. Set to\n",
    "    # \"dummy\" for parallel environments to be called in a for loop on a single process,\n",
    "    # or to \"subproc\" for parallel environments running in separate processes.\n",
    "    \"vec_env\": \"subproc\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your RL agent\n",
    "\n",
    "Below is the code for training the RL agent with the PPO algorithm as implemented in _Stable Baselines3_. You probably shouldn't change this cell unless you know what you are doing. If you want to use a different algorithm, you will need to change the code below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlink80\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Path .wandb/wandb/ wasn't writable, using system temp directory.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/var/folders/5d/kybqtr6j2w5_zhtdddx09xcw0000gn/T/wandb/run-20250402_143847-rfdgxzm2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/link80/rl4aa25-challenge/runs/rfdgxzm2' target=\"_blank\">apricot-plant-9</a></strong> to <a href='https://wandb.ai/link80/rl4aa25-challenge' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/link80/rl4aa25-challenge' target=\"_blank\">https://wandb.ai/link80/rl4aa25-challenge</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/link80/rl4aa25-challenge/runs/rfdgxzm2' target=\"_blank\">https://wandb.ai/link80/rl4aa25-challenge/runs/rfdgxzm2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to log/apricot-plant-9/PPO_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannesvoss/miniforge3/envs/rl4aa25-challenge/lib/python3.11/site-packages/stable_baselines3/common/callbacks.py:418: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x15450a690> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x154531310>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -0.381   |\n",
      "| time/              |          |\n",
      "|    fps             | 2429     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2560     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.398      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1730        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018704781 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.06       |\n",
      "|    explained_variance   | -2.43       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00682     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.405      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1586        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 7680        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016804254 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.99       |\n",
      "|    explained_variance   | -1.25       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0384     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    std                  | 0.979       |\n",
      "|    value_loss           | 0.0107      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-0.45 +/- 0.13\n",
      "Episode length: 50.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 50         |\n",
      "|    mean_reward          | -0.452     |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 10000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01806439 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.92      |\n",
      "|    explained_variance   | -0.39      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0702    |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0397    |\n",
      "|    std                  | 0.961      |\n",
      "|    value_loss           | 0.00378    |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -0.391   |\n",
      "| time/              |          |\n",
      "|    fps             | 585      |\n",
      "|    iterations      | 4        |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.387      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 662         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 12800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019282985 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.88       |\n",
      "|    explained_variance   | -0.397      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0557     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0435     |\n",
      "|    std                  | 0.956       |\n",
      "|    value_loss           | 0.00211     |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 50        |\n",
      "|    ep_rew_mean          | -0.367    |\n",
      "| time/                   |           |\n",
      "|    fps                  | 723       |\n",
      "|    iterations           | 6         |\n",
      "|    time_elapsed         | 21        |\n",
      "|    total_timesteps      | 15360     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0201598 |\n",
      "|    clip_fraction        | 0.232     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.86     |\n",
      "|    explained_variance   | -0.409    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0546   |\n",
      "|    n_updates            | 250       |\n",
      "|    policy_gradient_loss | -0.0461   |\n",
      "|    std                  | 0.952     |\n",
      "|    value_loss           | 0.00164   |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.342      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 770         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 17920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024136323 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.78       |\n",
      "|    explained_variance   | -0.136      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0635     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0484     |\n",
      "|    std                  | 0.935       |\n",
      "|    value_loss           | 0.000973    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-0.16 +/- 0.02\n",
      "Episode length: 50.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 50          |\n",
      "|    mean_reward          | -0.158      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024343863 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.69       |\n",
      "|    explained_variance   | 0.0391      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0578     |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0498     |\n",
      "|    std                  | 0.918       |\n",
      "|    value_loss           | 0.00118     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -0.339   |\n",
      "| time/              |          |\n",
      "|    fps             | 577      |\n",
      "|    iterations      | 8        |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.323      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 616         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 23040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023615858 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.62       |\n",
      "|    explained_variance   | -0.089      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0732     |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0503     |\n",
      "|    std                  | 0.907       |\n",
      "|    value_loss           | 0.00103     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.297      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 653         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025656965 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.51       |\n",
      "|    explained_variance   | -0.111      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0588     |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.051      |\n",
      "|    std                  | 0.885       |\n",
      "|    value_loss           | 0.000812    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.284     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 685        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 41         |\n",
      "|    total_timesteps      | 28160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02592124 |\n",
      "|    clip_fraction        | 0.292      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.42      |\n",
      "|    explained_variance   | -0.0448    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0801    |\n",
      "|    n_updates            | 500        |\n",
      "|    policy_gradient_loss | -0.0535    |\n",
      "|    std                  | 0.871      |\n",
      "|    value_loss           | 0.000561   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-0.20 +/- 0.03\n",
      "Episode length: 50.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 50          |\n",
      "|    mean_reward          | -0.199      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 30000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024528544 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.33       |\n",
      "|    explained_variance   | -0.0131     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0574     |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0525     |\n",
      "|    std                  | 0.855       |\n",
      "|    value_loss           | 0.000528    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -0.278   |\n",
      "| time/              |          |\n",
      "|    fps             | 576      |\n",
      "|    iterations      | 12       |\n",
      "|    time_elapsed    | 53       |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.278     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 602        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 55         |\n",
      "|    total_timesteps      | 33280      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03081962 |\n",
      "|    clip_fraction        | 0.314      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.22      |\n",
      "|    explained_variance   | 0.0364     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0874    |\n",
      "|    n_updates            | 600        |\n",
      "|    policy_gradient_loss | -0.0569    |\n",
      "|    std                  | 0.838      |\n",
      "|    value_loss           | 0.000543   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.263      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 626         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030699318 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.12       |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0676     |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0605     |\n",
      "|    std                  | 0.819       |\n",
      "|    value_loss           | 0.000568    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.241     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 649        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 59         |\n",
      "|    total_timesteps      | 38400      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03062591 |\n",
      "|    clip_fraction        | 0.327      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.05      |\n",
      "|    explained_variance   | 0.192      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.055     |\n",
      "|    n_updates            | 700        |\n",
      "|    policy_gradient_loss | -0.056     |\n",
      "|    std                  | 0.809      |\n",
      "|    value_loss           | 0.000501   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-0.17 +/- 0.06\n",
      "Episode length: 50.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 50          |\n",
      "|    mean_reward          | -0.175      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029796138 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.98       |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0704     |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.057      |\n",
      "|    std                  | 0.799       |\n",
      "|    value_loss           | 0.000362    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -0.227   |\n",
      "| time/              |          |\n",
      "|    fps             | 574      |\n",
      "|    iterations      | 16       |\n",
      "|    time_elapsed    | 71       |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.219      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 594         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 43520       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031204712 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.9        |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0782     |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0598     |\n",
      "|    std                  | 0.785       |\n",
      "|    value_loss           | 0.000218    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.212      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 613         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028204639 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.062      |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.053      |\n",
      "|    std                  | 0.773       |\n",
      "|    value_loss           | 0.000311    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.203     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 631        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 77         |\n",
      "|    total_timesteps      | 48640      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03122149 |\n",
      "|    clip_fraction        | 0.323      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.71      |\n",
      "|    explained_variance   | 0.486      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0735    |\n",
      "|    n_updates            | 900        |\n",
      "|    policy_gradient_loss | -0.0562    |\n",
      "|    std                  | 0.758      |\n",
      "|    value_loss           | 0.000301   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-0.15 +/- 0.07\n",
      "Episode length: 50.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 50          |\n",
      "|    mean_reward          | -0.153      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033133768 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.62       |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0999     |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0587     |\n",
      "|    std                  | 0.745       |\n",
      "|    value_loss           | 0.000246    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -0.194   |\n",
      "| time/              |          |\n",
      "|    fps             | 572      |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 89       |\n",
      "|    total_timesteps | 51200    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.184      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 588         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 53760       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033692975 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.52       |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0529     |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.0569     |\n",
      "|    std                  | 0.73        |\n",
      "|    value_loss           | 0.000341    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.183      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 604         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032158863 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.44       |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0578     |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.0572     |\n",
      "|    std                  | 0.72        |\n",
      "|    value_loss           | 0.000309    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.177     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 619        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 95         |\n",
      "|    total_timesteps      | 58880      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03451444 |\n",
      "|    clip_fraction        | 0.335      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.38      |\n",
      "|    explained_variance   | 0.652      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0702    |\n",
      "|    n_updates            | 1100       |\n",
      "|    policy_gradient_loss | -0.06      |\n",
      "|    std                  | 0.71       |\n",
      "|    value_loss           | 0.000322   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-0.13 +/- 0.05\n",
      "Episode length: 50.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 50          |\n",
      "|    mean_reward          | -0.132      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 60000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036151774 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.3        |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0789     |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.0568     |\n",
      "|    std                  | 0.698       |\n",
      "|    value_loss           | 0.00029     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -0.181   |\n",
      "| time/              |          |\n",
      "|    fps             | 572      |\n",
      "|    iterations      | 24       |\n",
      "|    time_elapsed    | 107      |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 50        |\n",
      "|    ep_rew_mean          | -0.18     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 586       |\n",
      "|    iterations           | 25        |\n",
      "|    time_elapsed         | 109       |\n",
      "|    total_timesteps      | 64000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0335825 |\n",
      "|    clip_fraction        | 0.324     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -5.19     |\n",
      "|    explained_variance   | 0.734     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0719   |\n",
      "|    n_updates            | 1200      |\n",
      "|    policy_gradient_loss | -0.0581   |\n",
      "|    std                  | 0.681     |\n",
      "|    value_loss           | 0.000358  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.167      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 599         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 66560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033977486 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.09       |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.091      |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | -0.0554     |\n",
      "|    std                  | 0.67        |\n",
      "|    value_loss           | 0.000231    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.166      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 612         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 69120       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034028977 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0589     |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.0535     |\n",
      "|    std                  | 0.659       |\n",
      "|    value_loss           | 0.000239    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-0.10 +/- 0.03\n",
      "Episode length: 50.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 50          |\n",
      "|    mean_reward          | -0.103      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 70000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042119805 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.96       |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0699     |\n",
      "|    n_updates            | 1350        |\n",
      "|    policy_gradient_loss | -0.0592     |\n",
      "|    std                  | 0.653       |\n",
      "|    value_loss           | 0.000262    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -0.176   |\n",
      "| time/              |          |\n",
      "|    fps             | 571      |\n",
      "|    iterations      | 28       |\n",
      "|    time_elapsed    | 125      |\n",
      "|    total_timesteps | 71680    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.169     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 583        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 127        |\n",
      "|    total_timesteps      | 74240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03193971 |\n",
      "|    clip_fraction        | 0.331      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.92      |\n",
      "|    explained_variance   | 0.781      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.084     |\n",
      "|    n_updates            | 1400       |\n",
      "|    policy_gradient_loss | -0.0568    |\n",
      "|    std                  | 0.649      |\n",
      "|    value_loss           | 0.000359   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.161     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 595        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 129        |\n",
      "|    total_timesteps      | 76800      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03714456 |\n",
      "|    clip_fraction        | 0.356      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.87      |\n",
      "|    explained_variance   | 0.705      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0961    |\n",
      "|    n_updates            | 1450       |\n",
      "|    policy_gradient_loss | -0.0585    |\n",
      "|    std                  | 0.643      |\n",
      "|    value_loss           | 0.000329   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.167      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 606         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 79360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034141626 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.82       |\n",
      "|    explained_variance   | 0.729       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0715     |\n",
      "|    n_updates            | 1500        |\n",
      "|    policy_gradient_loss | -0.0549     |\n",
      "|    std                  | 0.636       |\n",
      "|    value_loss           | 0.000339    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-0.11 +/- 0.02\n",
      "Episode length: 50.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 50         |\n",
      "|    mean_reward          | -0.113     |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 80000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03606263 |\n",
      "|    clip_fraction        | 0.354      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.72      |\n",
      "|    explained_variance   | 0.747      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.04      |\n",
      "|    n_updates            | 1550       |\n",
      "|    policy_gradient_loss | -0.056     |\n",
      "|    std                  | 0.622      |\n",
      "|    value_loss           | 0.000374   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -0.162   |\n",
      "| time/              |          |\n",
      "|    fps             | 572      |\n",
      "|    iterations      | 32       |\n",
      "|    time_elapsed    | 143      |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.155     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 582        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 144        |\n",
      "|    total_timesteps      | 84480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03535334 |\n",
      "|    clip_fraction        | 0.343      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.62      |\n",
      "|    explained_variance   | 0.8        |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0657    |\n",
      "|    n_updates            | 1600       |\n",
      "|    policy_gradient_loss | -0.0548    |\n",
      "|    std                  | 0.61       |\n",
      "|    value_loss           | 0.000273   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.168      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 593         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 87040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042123564 |\n",
      "|    clip_fraction        | 0.366       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.58       |\n",
      "|    explained_variance   | 0.827       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0724     |\n",
      "|    n_updates            | 1650        |\n",
      "|    policy_gradient_loss | -0.0577     |\n",
      "|    std                  | 0.606       |\n",
      "|    value_loss           | 0.000314    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.171      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 602         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 89600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038025506 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.54       |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0741     |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | -0.0604     |\n",
      "|    std                  | 0.599       |\n",
      "|    value_loss           | 0.000414    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=-0.15 +/- 0.03\n",
      "Episode length: 50.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 50          |\n",
      "|    mean_reward          | -0.146      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 90000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043272693 |\n",
      "|    clip_fraction        | 0.372       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.47       |\n",
      "|    explained_variance   | 0.768       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0755     |\n",
      "|    n_updates            | 1750        |\n",
      "|    policy_gradient_loss | -0.0598     |\n",
      "|    std                  | 0.592       |\n",
      "|    value_loss           | 0.000315    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -0.163   |\n",
      "| time/              |          |\n",
      "|    fps             | 572      |\n",
      "|    iterations      | 36       |\n",
      "|    time_elapsed    | 160      |\n",
      "|    total_timesteps | 92160    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.161      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 582         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 162         |\n",
      "|    total_timesteps      | 94720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043491412 |\n",
      "|    clip_fraction        | 0.376       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.39       |\n",
      "|    explained_variance   | 0.784       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0623     |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -0.0592     |\n",
      "|    std                  | 0.581       |\n",
      "|    value_loss           | 0.000419    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.159      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 591         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 97280       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042682774 |\n",
      "|    clip_fraction        | 0.376       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.26       |\n",
      "|    explained_variance   | 0.801       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0802     |\n",
      "|    n_updates            | 1850        |\n",
      "|    policy_gradient_loss | -0.0582     |\n",
      "|    std                  | 0.565       |\n",
      "|    value_loss           | 0.000389    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.157     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 600        |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 166        |\n",
      "|    total_timesteps      | 99840      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04850992 |\n",
      "|    clip_fraction        | 0.408      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.15      |\n",
      "|    explained_variance   | 0.764      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0635    |\n",
      "|    n_updates            | 1900       |\n",
      "|    policy_gradient_loss | -0.0625    |\n",
      "|    std                  | 0.555      |\n",
      "|    value_loss           | 0.000302   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-0.12 +/- 0.05\n",
      "Episode length: 50.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 50          |\n",
      "|    mean_reward          | -0.117      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040570874 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.1        |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0576     |\n",
      "|    n_updates            | 1950        |\n",
      "|    policy_gradient_loss | -0.0574     |\n",
      "|    std                  | 0.549       |\n",
      "|    value_loss           | 0.000305    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -0.164   |\n",
      "| time/              |          |\n",
      "|    fps             | 573      |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 178      |\n",
      "|    total_timesteps | 102400   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.162      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 581         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 104960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046696696 |\n",
      "|    clip_fraction        | 0.383       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.04       |\n",
      "|    explained_variance   | 0.796       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0762     |\n",
      "|    n_updates            | 2000        |\n",
      "|    policy_gradient_loss | -0.0609     |\n",
      "|    std                  | 0.543       |\n",
      "|    value_loss           | 0.000354    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.156      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 182         |\n",
      "|    total_timesteps      | 107520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045013946 |\n",
      "|    clip_fraction        | 0.386       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.94       |\n",
      "|    explained_variance   | 0.833       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0786     |\n",
      "|    n_updates            | 2050        |\n",
      "|    policy_gradient_loss | -0.0605     |\n",
      "|    std                  | 0.532       |\n",
      "|    value_loss           | 0.000311    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=-0.15 +/- 0.02\n",
      "Episode length: 50.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 50          |\n",
      "|    mean_reward          | -0.146      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 110000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049294837 |\n",
      "|    clip_fraction        | 0.417       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.82       |\n",
      "|    explained_variance   | 0.805       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0499     |\n",
      "|    n_updates            | 2100        |\n",
      "|    policy_gradient_loss | -0.0622     |\n",
      "|    std                  | 0.52        |\n",
      "|    value_loss           | 0.000399    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -0.158   |\n",
      "| time/              |          |\n",
      "|    fps             | 539      |\n",
      "|    iterations      | 43       |\n",
      "|    time_elapsed    | 203      |\n",
      "|    total_timesteps | 110080   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.154      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 547         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052298672 |\n",
      "|    clip_fraction        | 0.406       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.75       |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0647     |\n",
      "|    n_updates            | 2150        |\n",
      "|    policy_gradient_loss | -0.0617     |\n",
      "|    std                  | 0.513       |\n",
      "|    value_loss           | 0.000493    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.149      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 554         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 115200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051231492 |\n",
      "|    clip_fraction        | 0.415       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.67       |\n",
      "|    explained_variance   | 0.822       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0458     |\n",
      "|    n_updates            | 2200        |\n",
      "|    policy_gradient_loss | -0.0601     |\n",
      "|    std                  | 0.505       |\n",
      "|    value_loss           | 0.000389    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.146      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 561         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 209         |\n",
      "|    total_timesteps      | 117760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053052295 |\n",
      "|    clip_fraction        | 0.422       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.59       |\n",
      "|    explained_variance   | 0.794       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0693     |\n",
      "|    n_updates            | 2250        |\n",
      "|    policy_gradient_loss | -0.0613     |\n",
      "|    std                  | 0.498       |\n",
      "|    value_loss           | 0.000363    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-0.12 +/- 0.03\n",
      "Episode length: 50.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 50          |\n",
      "|    mean_reward          | -0.119      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 120000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050034724 |\n",
      "|    clip_fraction        | 0.403       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.51       |\n",
      "|    explained_variance   | 0.825       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0802     |\n",
      "|    n_updates            | 2300        |\n",
      "|    policy_gradient_loss | -0.0626     |\n",
      "|    std                  | 0.488       |\n",
      "|    value_loss           | 0.000355    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -0.15    |\n",
      "| time/              |          |\n",
      "|    fps             | 481      |\n",
      "|    iterations      | 47       |\n",
      "|    time_elapsed    | 249      |\n",
      "|    total_timesteps | 120320   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.145      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 487         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 251         |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057642303 |\n",
      "|    clip_fraction        | 0.436       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.41       |\n",
      "|    explained_variance   | 0.832       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0978     |\n",
      "|    n_updates            | 2350        |\n",
      "|    policy_gradient_loss | -0.0641     |\n",
      "|    std                  | 0.477       |\n",
      "|    value_loss           | 0.000372    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.131     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 494        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 253        |\n",
      "|    total_timesteps      | 125440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05651434 |\n",
      "|    clip_fraction        | 0.431      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.26      |\n",
      "|    explained_variance   | 0.845      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0752    |\n",
      "|    n_updates            | 2400       |\n",
      "|    policy_gradient_loss | -0.0546    |\n",
      "|    std                  | 0.465      |\n",
      "|    value_loss           | 0.000289   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.135      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 255         |\n",
      "|    total_timesteps      | 128000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059126757 |\n",
      "|    clip_fraction        | 0.407       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.861       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0858     |\n",
      "|    n_updates            | 2450        |\n",
      "|    policy_gradient_loss | -0.0586     |\n",
      "|    std                  | 0.452       |\n",
      "|    value_loss           | 0.00029     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=-0.12 +/- 0.05\n",
      "Episode length: 50.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 50         |\n",
      "|    mean_reward          | -0.121     |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 130000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05179124 |\n",
      "|    clip_fraction        | 0.423      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.01      |\n",
      "|    explained_variance   | 0.851      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0672    |\n",
      "|    n_updates            | 2500       |\n",
      "|    policy_gradient_loss | -0.0576    |\n",
      "|    std                  | 0.442      |\n",
      "|    value_loss           | 0.00032    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -0.143   |\n",
      "| time/              |          |\n",
      "|    fps             | 486      |\n",
      "|    iterations      | 51       |\n",
      "|    time_elapsed    | 268      |\n",
      "|    total_timesteps | 130560   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.149      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 492         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 270         |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054173686 |\n",
      "|    clip_fraction        | 0.429       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.95       |\n",
      "|    explained_variance   | 0.831       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0715     |\n",
      "|    n_updates            | 2550        |\n",
      "|    policy_gradient_loss | -0.0587     |\n",
      "|    std                  | 0.437       |\n",
      "|    value_loss           | 0.000496    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.141      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 498         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 272         |\n",
      "|    total_timesteps      | 135680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.064766325 |\n",
      "|    clip_fraction        | 0.441       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.88       |\n",
      "|    explained_variance   | 0.837       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0737     |\n",
      "|    n_updates            | 2600        |\n",
      "|    policy_gradient_loss | -0.0614     |\n",
      "|    std                  | 0.433       |\n",
      "|    value_loss           | 0.000402    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.138     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 504        |\n",
      "|    iterations           | 54         |\n",
      "|    time_elapsed         | 273        |\n",
      "|    total_timesteps      | 138240     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05991022 |\n",
      "|    clip_fraction        | 0.437      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.84      |\n",
      "|    explained_variance   | 0.813      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.076     |\n",
      "|    n_updates            | 2650       |\n",
      "|    policy_gradient_loss | -0.0641    |\n",
      "|    std                  | 0.428      |\n",
      "|    value_loss           | 0.000418   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=-0.13 +/- 0.05\n",
      "Episode length: 50.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 50         |\n",
      "|    mean_reward          | -0.128     |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 140000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05707754 |\n",
      "|    clip_fraction        | 0.431      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.76      |\n",
      "|    explained_variance   | 0.86       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0603    |\n",
      "|    n_updates            | 2700       |\n",
      "|    policy_gradient_loss | -0.0563    |\n",
      "|    std                  | 0.421      |\n",
      "|    value_loss           | 0.000338   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -0.138   |\n",
      "| time/              |          |\n",
      "|    fps             | 491      |\n",
      "|    iterations      | 55       |\n",
      "|    time_elapsed    | 286      |\n",
      "|    total_timesteps | 140800   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.135     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 496        |\n",
      "|    iterations           | 56         |\n",
      "|    time_elapsed         | 288        |\n",
      "|    total_timesteps      | 143360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05588652 |\n",
      "|    clip_fraction        | 0.415      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.72      |\n",
      "|    explained_variance   | 0.842      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.085     |\n",
      "|    n_updates            | 2750       |\n",
      "|    policy_gradient_loss | -0.0561    |\n",
      "|    std                  | 0.418      |\n",
      "|    value_loss           | 0.000425   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.131      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 290         |\n",
      "|    total_timesteps      | 145920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059268605 |\n",
      "|    clip_fraction        | 0.429       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | 0.871       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0851     |\n",
      "|    n_updates            | 2800        |\n",
      "|    policy_gradient_loss | -0.057      |\n",
      "|    std                  | 0.409       |\n",
      "|    value_loss           | 0.000256    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.136      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 292         |\n",
      "|    total_timesteps      | 148480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059120584 |\n",
      "|    clip_fraction        | 0.436       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.52       |\n",
      "|    explained_variance   | 0.875       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0707     |\n",
      "|    n_updates            | 2850        |\n",
      "|    policy_gradient_loss | -0.0577     |\n",
      "|    std                  | 0.401       |\n",
      "|    value_loss           | 0.000313    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=-0.17 +/- 0.07\n",
      "Episode length: 50.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 50          |\n",
      "|    mean_reward          | -0.174      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 150000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057288706 |\n",
      "|    clip_fraction        | 0.439       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.45       |\n",
      "|    explained_variance   | 0.834       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0788     |\n",
      "|    n_updates            | 2900        |\n",
      "|    policy_gradient_loss | -0.0582     |\n",
      "|    std                  | 0.395       |\n",
      "|    value_loss           | 0.000396    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -0.134   |\n",
      "| time/              |          |\n",
      "|    fps             | 495      |\n",
      "|    iterations      | 59       |\n",
      "|    time_elapsed    | 304      |\n",
      "|    total_timesteps | 151040   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.131      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 306         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053887594 |\n",
      "|    clip_fraction        | 0.431       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.37       |\n",
      "|    explained_variance   | 0.871       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0811     |\n",
      "|    n_updates            | 2950        |\n",
      "|    policy_gradient_loss | -0.0528     |\n",
      "|    std                  | 0.39        |\n",
      "|    value_loss           | 0.000259    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.129     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 506        |\n",
      "|    iterations           | 61         |\n",
      "|    time_elapsed         | 308        |\n",
      "|    total_timesteps      | 156160     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06418886 |\n",
      "|    clip_fraction        | 0.446      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.29      |\n",
      "|    explained_variance   | 0.879      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0635    |\n",
      "|    n_updates            | 3000       |\n",
      "|    policy_gradient_loss | -0.0578    |\n",
      "|    std                  | 0.383      |\n",
      "|    value_loss           | 0.0003     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.133     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 511        |\n",
      "|    iterations           | 62         |\n",
      "|    time_elapsed         | 310        |\n",
      "|    total_timesteps      | 158720     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06454022 |\n",
      "|    clip_fraction        | 0.451      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.19      |\n",
      "|    explained_variance   | 0.883      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.066     |\n",
      "|    n_updates            | 3050       |\n",
      "|    policy_gradient_loss | -0.0543    |\n",
      "|    std                  | 0.375      |\n",
      "|    value_loss           | 0.000331   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=-0.11 +/- 0.02\n",
      "Episode length: 50.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 50          |\n",
      "|    mean_reward          | -0.113      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 160000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.065327846 |\n",
      "|    clip_fraction        | 0.47        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.1        |\n",
      "|    explained_variance   | 0.876       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0853     |\n",
      "|    n_updates            | 3100        |\n",
      "|    policy_gradient_loss | -0.0608     |\n",
      "|    std                  | 0.369       |\n",
      "|    value_loss           | 0.000442    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -0.133   |\n",
      "| time/              |          |\n",
      "|    fps             | 499      |\n",
      "|    iterations      | 63       |\n",
      "|    time_elapsed    | 322      |\n",
      "|    total_timesteps | 161280   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.125     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 504        |\n",
      "|    iterations           | 64         |\n",
      "|    time_elapsed         | 324        |\n",
      "|    total_timesteps      | 163840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07627182 |\n",
      "|    clip_fraction        | 0.487      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.99      |\n",
      "|    explained_variance   | 0.877      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0677    |\n",
      "|    n_updates            | 3150       |\n",
      "|    policy_gradient_loss | -0.058     |\n",
      "|    std                  | 0.36       |\n",
      "|    value_loss           | 0.000372   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.131     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 509        |\n",
      "|    iterations           | 65         |\n",
      "|    time_elapsed         | 326        |\n",
      "|    total_timesteps      | 166400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06661886 |\n",
      "|    clip_fraction        | 0.464      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.92      |\n",
      "|    explained_variance   | 0.897      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0758    |\n",
      "|    n_updates            | 3200       |\n",
      "|    policy_gradient_loss | -0.0584    |\n",
      "|    std                  | 0.354      |\n",
      "|    value_loss           | 0.000346   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 50        |\n",
      "|    ep_rew_mean          | -0.128    |\n",
      "| time/                   |           |\n",
      "|    fps                  | 514       |\n",
      "|    iterations           | 66        |\n",
      "|    time_elapsed         | 328       |\n",
      "|    total_timesteps      | 168960    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0682614 |\n",
      "|    clip_fraction        | 0.458     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.81     |\n",
      "|    explained_variance   | 0.869     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0478   |\n",
      "|    n_updates            | 3250      |\n",
      "|    policy_gradient_loss | -0.0594   |\n",
      "|    std                  | 0.346     |\n",
      "|    value_loss           | 0.000471  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=-0.12 +/- 0.03\n",
      "Episode length: 50.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 50         |\n",
      "|    mean_reward          | -0.12      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 170000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06742637 |\n",
      "|    clip_fraction        | 0.467      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.69      |\n",
      "|    explained_variance   | 0.872      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.086     |\n",
      "|    n_updates            | 3300       |\n",
      "|    policy_gradient_loss | -0.059     |\n",
      "|    std                  | 0.339      |\n",
      "|    value_loss           | 0.000408   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -0.138   |\n",
      "| time/              |          |\n",
      "|    fps             | 503      |\n",
      "|    iterations      | 67       |\n",
      "|    time_elapsed    | 340      |\n",
      "|    total_timesteps | 171520   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.138     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 507        |\n",
      "|    iterations           | 68         |\n",
      "|    time_elapsed         | 342        |\n",
      "|    total_timesteps      | 174080     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07815432 |\n",
      "|    clip_fraction        | 0.464      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.59      |\n",
      "|    explained_variance   | 0.843      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0603    |\n",
      "|    n_updates            | 3350       |\n",
      "|    policy_gradient_loss | -0.0631    |\n",
      "|    std                  | 0.331      |\n",
      "|    value_loss           | 0.000554   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.127     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 512        |\n",
      "|    iterations           | 69         |\n",
      "|    time_elapsed         | 344        |\n",
      "|    total_timesteps      | 176640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07655291 |\n",
      "|    clip_fraction        | 0.469      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.53      |\n",
      "|    explained_variance   | 0.884      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0573    |\n",
      "|    n_updates            | 3400       |\n",
      "|    policy_gradient_loss | -0.059     |\n",
      "|    std                  | 0.328      |\n",
      "|    value_loss           | 0.000548   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.123     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 516        |\n",
      "|    iterations           | 70         |\n",
      "|    time_elapsed         | 346        |\n",
      "|    total_timesteps      | 179200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08084445 |\n",
      "|    clip_fraction        | 0.502      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.47      |\n",
      "|    explained_variance   | 0.851      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0793    |\n",
      "|    n_updates            | 3450       |\n",
      "|    policy_gradient_loss | -0.0577    |\n",
      "|    std                  | 0.325      |\n",
      "|    value_loss           | 0.000428   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=-0.11 +/- 0.03\n",
      "Episode length: 50.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 50        |\n",
      "|    mean_reward          | -0.109    |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 180000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0695006 |\n",
      "|    clip_fraction        | 0.476     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.39     |\n",
      "|    explained_variance   | 0.893     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.086    |\n",
      "|    n_updates            | 3500      |\n",
      "|    policy_gradient_loss | -0.0594   |\n",
      "|    std                  | 0.319     |\n",
      "|    value_loss           | 0.000419  |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -0.13    |\n",
      "| time/              |          |\n",
      "|    fps             | 505      |\n",
      "|    iterations      | 71       |\n",
      "|    time_elapsed    | 359      |\n",
      "|    total_timesteps | 181760   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.136      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 361         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.081128575 |\n",
      "|    clip_fraction        | 0.498       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.88        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0937     |\n",
      "|    n_updates            | 3550        |\n",
      "|    policy_gradient_loss | -0.0617     |\n",
      "|    std                  | 0.311       |\n",
      "|    value_loss           | 0.000432    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.135     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 514        |\n",
      "|    iterations           | 73         |\n",
      "|    time_elapsed         | 363        |\n",
      "|    total_timesteps      | 186880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07582079 |\n",
      "|    clip_fraction        | 0.473      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.19      |\n",
      "|    explained_variance   | 0.906      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0915    |\n",
      "|    n_updates            | 3600       |\n",
      "|    policy_gradient_loss | -0.0606    |\n",
      "|    std                  | 0.306      |\n",
      "|    value_loss           | 0.000435   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.131      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 518         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 365         |\n",
      "|    total_timesteps      | 189440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.085831314 |\n",
      "|    clip_fraction        | 0.498       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.867       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0842     |\n",
      "|    n_updates            | 3650        |\n",
      "|    policy_gradient_loss | -0.0618     |\n",
      "|    std                  | 0.299       |\n",
      "|    value_loss           | 0.000446    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=190000, episode_reward=-0.11 +/- 0.02\n",
      "Episode length: 50.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 50          |\n",
      "|    mean_reward          | -0.11       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 190000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.087289415 |\n",
      "|    clip_fraction        | 0.499       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.995      |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0644     |\n",
      "|    n_updates            | 3700        |\n",
      "|    policy_gradient_loss | -0.0591     |\n",
      "|    std                  | 0.295       |\n",
      "|    value_loss           | 0.000419    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -0.124   |\n",
      "| time/              |          |\n",
      "|    fps             | 508      |\n",
      "|    iterations      | 75       |\n",
      "|    time_elapsed    | 377      |\n",
      "|    total_timesteps | 192000   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.134     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 512        |\n",
      "|    iterations           | 76         |\n",
      "|    time_elapsed         | 379        |\n",
      "|    total_timesteps      | 194560     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09661545 |\n",
      "|    clip_fraction        | 0.503      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.883     |\n",
      "|    explained_variance   | 0.91       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0627    |\n",
      "|    n_updates            | 3750       |\n",
      "|    policy_gradient_loss | -0.0556    |\n",
      "|    std                  | 0.288      |\n",
      "|    value_loss           | 0.00024    |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 50        |\n",
      "|    ep_rew_mean          | -0.138    |\n",
      "| time/                   |           |\n",
      "|    fps                  | 516       |\n",
      "|    iterations           | 77        |\n",
      "|    time_elapsed         | 381       |\n",
      "|    total_timesteps      | 197120    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1683878 |\n",
      "|    clip_fraction        | 0.499     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.79     |\n",
      "|    explained_variance   | 0.851     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0753   |\n",
      "|    n_updates            | 3800      |\n",
      "|    policy_gradient_loss | -0.0583   |\n",
      "|    std                  | 0.282     |\n",
      "|    value_loss           | 0.000464  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.136      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 383         |\n",
      "|    total_timesteps      | 199680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.090901926 |\n",
      "|    clip_fraction        | 0.485       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.761      |\n",
      "|    explained_variance   | 0.881       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0654     |\n",
      "|    n_updates            | 3850        |\n",
      "|    policy_gradient_loss | -0.0575     |\n",
      "|    std                  | 0.281       |\n",
      "|    value_loss           | 0.000387    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=-0.16 +/- 0.07\n",
      "Episode length: 50.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 50          |\n",
      "|    mean_reward          | -0.158      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 200000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.090912595 |\n",
      "|    clip_fraction        | 0.517       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.71       |\n",
      "|    explained_variance   | 0.871       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.066      |\n",
      "|    n_updates            | 3900        |\n",
      "|    policy_gradient_loss | -0.063      |\n",
      "|    std                  | 0.279       |\n",
      "|    value_loss           | 0.000556    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -0.134   |\n",
      "| time/              |          |\n",
      "|    fps             | 510      |\n",
      "|    iterations      | 79       |\n",
      "|    time_elapsed    | 395      |\n",
      "|    total_timesteps | 202240   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 397         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.082341775 |\n",
      "|    clip_fraction        | 0.509       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.65       |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0578     |\n",
      "|    n_updates            | 3950        |\n",
      "|    policy_gradient_loss | -0.0565     |\n",
      "|    std                  | 0.275       |\n",
      "|    value_loss           | 0.000394    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 50        |\n",
      "|    ep_rew_mean          | -0.136    |\n",
      "| time/                   |           |\n",
      "|    fps                  | 518       |\n",
      "|    iterations           | 81        |\n",
      "|    time_elapsed         | 399       |\n",
      "|    total_timesteps      | 207360    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0952662 |\n",
      "|    clip_fraction        | 0.529     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.541    |\n",
      "|    explained_variance   | 0.914     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0588   |\n",
      "|    n_updates            | 4000      |\n",
      "|    policy_gradient_loss | -0.0647   |\n",
      "|    std                  | 0.268     |\n",
      "|    value_loss           | 0.000416  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 50        |\n",
      "|    ep_rew_mean          | -0.134    |\n",
      "| time/                   |           |\n",
      "|    fps                  | 522       |\n",
      "|    iterations           | 82        |\n",
      "|    time_elapsed         | 401       |\n",
      "|    total_timesteps      | 209920    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1149625 |\n",
      "|    clip_fraction        | 0.516     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.449    |\n",
      "|    explained_variance   | 0.909     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0652   |\n",
      "|    n_updates            | 4050      |\n",
      "|    policy_gradient_loss | -0.0582   |\n",
      "|    std                  | 0.263     |\n",
      "|    value_loss           | 0.000333  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=-0.10 +/- 0.02\n",
      "Episode length: 50.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 50         |\n",
      "|    mean_reward          | -0.103     |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 210000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09511761 |\n",
      "|    clip_fraction        | 0.512      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.356     |\n",
      "|    explained_variance   | 0.909      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0812    |\n",
      "|    n_updates            | 4100       |\n",
      "|    policy_gradient_loss | -0.0607    |\n",
      "|    std                  | 0.259      |\n",
      "|    value_loss           | 0.000398   |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -0.14    |\n",
      "| time/              |          |\n",
      "|    fps             | 513      |\n",
      "|    iterations      | 83       |\n",
      "|    time_elapsed    | 413      |\n",
      "|    total_timesteps | 212480   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.136     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 517        |\n",
      "|    iterations           | 84         |\n",
      "|    time_elapsed         | 415        |\n",
      "|    total_timesteps      | 215040     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11288998 |\n",
      "|    clip_fraction        | 0.516      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.247     |\n",
      "|    explained_variance   | 0.802      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0629    |\n",
      "|    n_updates            | 4150       |\n",
      "|    policy_gradient_loss | -0.0607    |\n",
      "|    std                  | 0.252      |\n",
      "|    value_loss           | 0.000447   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.127      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 521         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 417         |\n",
      "|    total_timesteps      | 217600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.091733895 |\n",
      "|    clip_fraction        | 0.516       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.117      |\n",
      "|    explained_variance   | 0.907       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0604     |\n",
      "|    n_updates            | 4200        |\n",
      "|    policy_gradient_loss | -0.0536     |\n",
      "|    std                  | 0.247       |\n",
      "|    value_loss           | 0.000346    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=-0.19 +/- 0.10\n",
      "Episode length: 50.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 50         |\n",
      "|    mean_reward          | -0.193     |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 220000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10903913 |\n",
      "|    clip_fraction        | 0.506      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0512    |\n",
      "|    explained_variance   | 0.894      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0726    |\n",
      "|    n_updates            | 4250       |\n",
      "|    policy_gradient_loss | -0.0605    |\n",
      "|    std                  | 0.243      |\n",
      "|    value_loss           | 0.000354   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -0.126   |\n",
      "| time/              |          |\n",
      "|    fps             | 512      |\n",
      "|    iterations      | 86       |\n",
      "|    time_elapsed    | 429      |\n",
      "|    total_timesteps | 220160   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.128     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 516        |\n",
      "|    iterations           | 87         |\n",
      "|    time_elapsed         | 431        |\n",
      "|    total_timesteps      | 222720     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14978799 |\n",
      "|    clip_fraction        | 0.524      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.0177     |\n",
      "|    explained_variance   | 0.897      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0571    |\n",
      "|    n_updates            | 4300       |\n",
      "|    policy_gradient_loss | -0.0552    |\n",
      "|    std                  | 0.24       |\n",
      "|    value_loss           | 0.000312   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.126     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 519        |\n",
      "|    iterations           | 88         |\n",
      "|    time_elapsed         | 433        |\n",
      "|    total_timesteps      | 225280     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09871697 |\n",
      "|    clip_fraction        | 0.53       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.105      |\n",
      "|    explained_variance   | 0.902      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0527    |\n",
      "|    n_updates            | 4350       |\n",
      "|    policy_gradient_loss | -0.0593    |\n",
      "|    std                  | 0.236      |\n",
      "|    value_loss           | 0.000354   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.12      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 523        |\n",
      "|    iterations           | 89         |\n",
      "|    time_elapsed         | 435        |\n",
      "|    total_timesteps      | 227840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14036402 |\n",
      "|    clip_fraction        | 0.523      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.205      |\n",
      "|    explained_variance   | 0.915      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0892    |\n",
      "|    n_updates            | 4400       |\n",
      "|    policy_gradient_loss | -0.0517    |\n",
      "|    std                  | 0.231      |\n",
      "|    value_loss           | 0.000314   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=-0.09 +/- 0.03\n",
      "Episode length: 50.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 50          |\n",
      "|    mean_reward          | -0.0926     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 230000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.119984604 |\n",
      "|    clip_fraction        | 0.556       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.325       |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0477     |\n",
      "|    n_updates            | 4450        |\n",
      "|    policy_gradient_loss | -0.0576     |\n",
      "|    std                  | 0.225       |\n",
      "|    value_loss           | 0.000305    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -0.116   |\n",
      "| time/              |          |\n",
      "|    fps             | 515      |\n",
      "|    iterations      | 90       |\n",
      "|    time_elapsed    | 447      |\n",
      "|    total_timesteps | 230400   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.118     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 518        |\n",
      "|    iterations           | 91         |\n",
      "|    time_elapsed         | 449        |\n",
      "|    total_timesteps      | 232960     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10884162 |\n",
      "|    clip_fraction        | 0.551      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.381      |\n",
      "|    explained_variance   | 0.883      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0734    |\n",
      "|    n_updates            | 4500       |\n",
      "|    policy_gradient_loss | -0.0568    |\n",
      "|    std                  | 0.224      |\n",
      "|    value_loss           | 0.000332   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.125     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 522        |\n",
      "|    iterations           | 92         |\n",
      "|    time_elapsed         | 451        |\n",
      "|    total_timesteps      | 235520     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11275071 |\n",
      "|    clip_fraction        | 0.53       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.472      |\n",
      "|    explained_variance   | 0.877      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0816    |\n",
      "|    n_updates            | 4550       |\n",
      "|    policy_gradient_loss | -0.0553    |\n",
      "|    std                  | 0.218      |\n",
      "|    value_loss           | 0.000336   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.131     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 525        |\n",
      "|    iterations           | 93         |\n",
      "|    time_elapsed         | 452        |\n",
      "|    total_timesteps      | 238080     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10905242 |\n",
      "|    clip_fraction        | 0.531      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.585      |\n",
      "|    explained_variance   | 0.877      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0645    |\n",
      "|    n_updates            | 4600       |\n",
      "|    policy_gradient_loss | -0.0544    |\n",
      "|    std                  | 0.214      |\n",
      "|    value_loss           | 0.000442   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=-0.15 +/- 0.08\n",
      "Episode length: 50.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 50         |\n",
      "|    mean_reward          | -0.151     |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 240000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10965456 |\n",
      "|    clip_fraction        | 0.538      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.662      |\n",
      "|    explained_variance   | 0.888      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0977    |\n",
      "|    n_updates            | 4650       |\n",
      "|    policy_gradient_loss | -0.0604    |\n",
      "|    std                  | 0.211      |\n",
      "|    value_loss           | 0.000545   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -0.134   |\n",
      "| time/              |          |\n",
      "|    fps             | 517      |\n",
      "|    iterations      | 94       |\n",
      "|    time_elapsed    | 464      |\n",
      "|    total_timesteps | 240640   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50         |\n",
      "|    ep_rew_mean          | -0.125     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 520        |\n",
      "|    iterations           | 95         |\n",
      "|    time_elapsed         | 466        |\n",
      "|    total_timesteps      | 243200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11595801 |\n",
      "|    clip_fraction        | 0.544      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.754      |\n",
      "|    explained_variance   | 0.92       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0835    |\n",
      "|    n_updates            | 4700       |\n",
      "|    policy_gradient_loss | -0.0516    |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 0.000362   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 50        |\n",
      "|    ep_rew_mean          | -0.117    |\n",
      "| time/                   |           |\n",
      "|    fps                  | 524       |\n",
      "|    iterations           | 96        |\n",
      "|    time_elapsed         | 468       |\n",
      "|    total_timesteps      | 245760    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1734619 |\n",
      "|    clip_fraction        | 0.575     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 0.857     |\n",
      "|    explained_variance   | 0.901     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0617   |\n",
      "|    n_updates            | 4750      |\n",
      "|    policy_gradient_loss | -0.0589   |\n",
      "|    std                  | 0.203     |\n",
      "|    value_loss           | 0.000489  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -0.118      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 527         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 470         |\n",
      "|    total_timesteps      | 248320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.112549186 |\n",
      "|    clip_fraction        | 0.565       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.937       |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0567     |\n",
      "|    n_updates            | 4800        |\n",
      "|    policy_gradient_loss | -0.0509     |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 0.000355    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=-0.17 +/- 0.07\n",
      "Episode length: 50.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 50          |\n",
      "|    mean_reward          | -0.169      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 250000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.120106496 |\n",
      "|    clip_fraction        | 0.548       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.05        |\n",
      "|    explained_variance   | 0.897       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0749     |\n",
      "|    n_updates            | 4850        |\n",
      "|    policy_gradient_loss | -0.0503     |\n",
      "|    std                  | 0.195       |\n",
      "|    value_loss           | 0.000413    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -0.125   |\n",
      "| time/              |          |\n",
      "|    fps             | 519      |\n",
      "|    iterations      | 98       |\n",
      "|    time_elapsed    | 482      |\n",
      "|    total_timesteps | 250880   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannesvoss/miniforge3/envs/rl4aa25-challenge/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:284: UserWarning: Path 'models/ea/ppo/apricot-plant-9' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n",
      "/Users/hannesvoss/Desktop/rl4aa25-challenge/src/wrappers/plot_episode.py:122: UserWarning: \u001b[33mWARN: Unable to generate episode plot for self.episode_id=125 because the episode was too short.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/hannesvoss/Desktop/rl4aa25-challenge/src/wrappers/log_task_statistics.py:71: UserWarning: \u001b[33mWARN: Unable to save episode plot for self.episode_id = 125 because the episode was too short.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# Setup wandb\n",
    "wandb.init(\n",
    "    project=\"rl4aa25-challenge\",\n",
    "    sync_tensorboard=True,\n",
    "    monitor_gym=True,\n",
    "    config=config,\n",
    "    dir=\".wandb\",\n",
    ")\n",
    "config = dict(wandb.config)\n",
    "config[\"run_name\"] = wandb.run.name\n",
    "\n",
    "# Setup vecorised environments for training and evaluation\n",
    "assert config[\"vec_env\"] in [\"dummy\", \"subproc\"]\n",
    "vec_env = (\n",
    "    DummyVecEnv([partial(make_env, config) for _ in range(config[\"n_envs\"])])\n",
    "    if config[\"vec_env\"] == \"dummy\"\n",
    "    else SubprocVecEnv([partial(make_env, config) for _ in range(config[\"n_envs\"])])\n",
    ")\n",
    "eval_vec_env = DummyVecEnv(\n",
    "    [partial(make_env, config, plot_episode=True, log_task_statistics=True)]\n",
    ")\n",
    "\n",
    "# Setup learning rate schedule if needed\n",
    "if config[\"lr_schedule\"] == \"linear\":\n",
    "    config[\"learning_rate\"] = linear_schedule(config[\"learning_rate\"])\n",
    "\n",
    "# Setup RL training algorithm\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    vec_env,\n",
    "    learning_rate=config[\"learning_rate\"],\n",
    "    n_steps=config[\"n_steps\"],\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    n_epochs=config[\"n_epochs\"],\n",
    "    gamma=config[\"gamma\"],\n",
    "    gae_lambda=config[\"gae_lambda\"],\n",
    "    clip_range=config[\"clip_range\"],\n",
    "    clip_range_vf=config[\"clip_range_vf\"],\n",
    "    ent_coef=config[\"ent_coef\"],\n",
    "    vf_coef=config[\"vf_coef\"],\n",
    "    max_grad_norm=config[\"max_grad_norm\"],\n",
    "    use_sde=config[\"use_sde\"],\n",
    "    sde_sample_freq=config[\"sde_sample_freq\"],\n",
    "    target_kl=config[\"target_kl\"],\n",
    "    policy_kwargs={\n",
    "        \"activation_fn\": getattr(nn, config[\"activation_fn\"]),\n",
    "        \"net_arch\": {  # From rl_zoo3\n",
    "            \"small\": {\"pi\": [64, 64], \"vf\": [64, 64]},\n",
    "            \"medium\": {\"pi\": [256, 256], \"vf\": [256, 256]},\n",
    "        }[config[\"net_arch\"]],\n",
    "        \"ortho_init\": config[\"ortho_init\"],\n",
    "        \"log_std_init\": config[\"log_std_init\"],\n",
    "    },\n",
    "    device=config[\"sb3_device\"],\n",
    "    tensorboard_log=f\"log/{config['run_name']}\",\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Setup callbacks for evaluation and logging\n",
    "eval_callback = EvalCallback(eval_vec_env, eval_freq=1_000, n_eval_episodes=5)\n",
    "wandb_callback = WandbCallback()\n",
    "\n",
    "# Train the model\n",
    "model.learn(\n",
    "    total_timesteps=config[\"total_timesteps\"],\n",
    "    callback=[eval_callback, wandb_callback],\n",
    ")\n",
    "\n",
    "# Save the model and associated configuration\n",
    "model.save(f\"models/ea/ppo/{wandb.run.name}/model\")\n",
    "save_config(config, f\"models/ea/ppo/{wandb.run.name}/config\")\n",
    "\n",
    "# Cleanup environments\n",
    "vec_env.close()\n",
    "eval_vec_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate your agent\n",
    "\n",
    "The following code snippet loads your trained policy and evaluates it on a number of randomly generated tuning problems. This is the task you actually need to solve for the challenge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = config[\"run_name\"]\n",
    "model_path = Path(\"models\") / \"ea\" / \"ppo\" / model_name\n",
    "model = PPO.load(model_path / \"model\")\n",
    "config = load_config(model_path / \"config\")\n",
    "\n",
    "evaluate_policy(model, config, write_data=True, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the results are loaded, shown to you and a CSV file is generated at `data/csvs/[model_name].csv`. This file is the one you need to submit to the challenge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = Study.load(f\"data/{model_name}\", name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final MAE: 785 Î¼m\n",
      "Steps to convergence: 150.0\n",
      "Sum of magnet changes: 124.31 \n",
      "--------------------\n",
      "Score: 1.1717\n"
     ]
    }
   ],
   "source": [
    "study.evaluate_challenge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may also admire your trained policy in action by running the following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1332.51x380.291 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = study.episodes[2].plot_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ† Upload your results to Kaggle\n",
    "\n",
    "For the chance to win the challenge prize. Go to `data/csvs/` and upload the CSV file via \\_\"Submit Prediction\" to the challenge submission page: https://www.kaggle.com/t/ad56a627d147405fa7b5c8629c8b7cf4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
